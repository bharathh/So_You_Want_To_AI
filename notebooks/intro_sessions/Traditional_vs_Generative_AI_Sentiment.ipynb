{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://toppng.com/uploads/preview/linkedin-logo-png-photo-116602552293wtc4qogql.png\" width=\"20\" height=\"20\" /> [Bharath Hemachandran](https://www.linkedin.com/in/bharath-hemachandran/)\n",
        "\n",
        "# üìä Traditional NLP vs Generative AI: Customer Sentiment\n",
        "\n",
        "This notebook teaches the **same task**‚Äî**customer sentiment classification**‚Äîdone two ways: **traditional NLP** (classical ML) and **generative AI**. Run each cell in order. Text cells explain; code cells run step by step.\n",
        "\n",
        "**Task:** Input = a short customer review. Output = **positive**, **negative**, or **neutral**.\n",
        "\n",
        "<div style=\"background: #e8f5e9; padding: 14px; border-radius: 8px; border-left: 4px solid #4caf50;\">\n",
        "<strong>üéØ What you'll do:</strong> Train a small TF-IDF + classifier on 12 reviews, compare with Groq on in-distribution and challenge examples, and see when the generative model should abstain.\n",
        "</div>\n",
        "\n",
        "### üìã Notebook objective (table of contents)\n",
        "\n",
        "This notebook covers:\n",
        "- **Fairness note** ‚Äî Why the setup is intentionally uneven (traditional vs generative)\n",
        "- **Setup** ‚Äî openai, scikit-learn; GROQ_API_KEY\n",
        "- **Data** ‚Äî Training, test (in-distribution), challenge (beyond training), should-abstain inputs\n",
        "- **Traditional NLP** ‚Äî TF-IDF + Logistic Regression pipeline; train on 12 reviews\n",
        "- **Part 1** ‚Äî In-distribution: both approaches on similar-to-training reviews\n",
        "- **Generative AI** ‚Äî Groq API with an instruction; no training for this task\n",
        "- **Part 2** ‚Äî Beyond training: negation, sarcasm, slang; traditional vs generative\n",
        "- **Part 3** ‚Äî Should abstain: empty/off-topic inputs; ideal behavior vs what happens\n",
        "- **Summary** ‚Äî Positives/negatives of generative AI; interpretability, cost, privacy, etc.\n",
        "- **Additional reading** ‚Äî Sentiment analysis and NLP resources\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öñÔ∏è Fairness note\n",
        "\n",
        "<div style=\"background: #fff3e0; padding: 12px; border-radius: 8px; border-left: 4px solid #ff9800;\">\n",
        "The setup is <strong>intentionally uneven</strong>: the traditional model is trained on <strong>12 examples</strong> here; the generative model is <strong>pre-trained on huge data</strong>. We are not claiming \"traditional is worse\"‚Äîwe are illustrating <strong>tradeoffs</strong> and <strong>strengths/weaknesses</strong> of each.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Setup (run once)\n",
        "\n",
        "Install `openai` and `scikit-learn`. On **Google Colab**, run this cell first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q openai scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üîë Set your Groq API key\n",
        "\n",
        "Get a free key at [console.groq.com](https://console.groq.com/keys). In Colab you can use **Secrets** (üîë) or run the cell below and paste when prompted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "if not os.environ.get(\"GROQ_API_KEY\"):\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass(\"Paste your GROQ_API_KEY: \")\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "def get_groq_client():\n",
        "    return OpenAI(\n",
        "        api_key=os.environ[\"GROQ_API_KEY\"],\n",
        "        base_url=\"https://api.groq.com/openai/v1\",\n",
        "    )\n",
        "\n",
        "print(\"Groq client ready (generative cells will use it).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÇ Data\n",
        "\n",
        "We use three sets:\n",
        "- **Training:** 12 labeled reviews (for the traditional model only).\n",
        "- **Test (in-distribution):** Reviews similar to training; both models should do OK.\n",
        "- **Challenge (beyond training):** Negation, sarcasm, slang‚Äîtraditional was never trained on these; generative can generalize.\n",
        "- **Should abstain:** Inputs that are *not* reviews (empty, question, off-topic); ideal behavior = abstain, but both often output a label anyway."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "REVIEWS_TRAIN = [\n",
        "    (\"The product is amazing, I love it!\", \"positive\"),\n",
        "    (\"Great product, very happy with my purchase.\", \"positive\"),\n",
        "    (\"Terrible experience, would not buy again.\", \"negative\"),\n",
        "    (\"It's okay, nothing special.\", \"neutral\"),\n",
        "    (\"Best purchase I've ever made. Highly recommend!\", \"positive\"),\n",
        "    (\"Waste of money. Broke after one day.\", \"negative\"),\n",
        "    (\"Complete waste of time and money.\", \"negative\"),\n",
        "    (\"Does what it says. No complaints.\", \"neutral\"),\n",
        "    (\"It works as described. Nothing more.\", \"neutral\"),\n",
        "    (\"Excellent quality and fast shipping.\", \"positive\"),\n",
        "    (\"Poor quality, very disappointed.\", \"negative\"),\n",
        "    (\"It's fine for the price.\", \"neutral\"),\n",
        "    (\"Absolutely love this! Five stars.\", \"positive\"),\n",
        "    (\"Worst product ever. Avoid.\", \"negative\"),\n",
        "    (\"Meets expectations. Average.\", \"neutral\"),\n",
        "]\n",
        "\n",
        "REVIEWS_TEST = [\n",
        "    \"Great product, very happy with my purchase.\",\n",
        "    \"Complete waste of time and money.\",\n",
        "    \"It works as described. Nothing more.\",\n",
        "]\n",
        "\n",
        "REVIEWS_CHALLENGE = [\n",
        "    (\"Not bad at all! Pleasantly surprised.\", \"positive\"),\n",
        "    (\"Oh great, another broken product. Just what I needed.\", \"negative\"),\n",
        "    (\"This slaps fr\", \"positive\"),\n",
        "    (\"mid tbh wouldn't buy again\", \"negative\"),\n",
        "    (\"It's okay I guess\", \"neutral\"),\n",
        "    (\"Actually way better than I expected\", \"positive\"),\n",
        "    (\"Meh.\", \"neutral\"),\n",
        "    (\"Wouldn't say I'm not happy with it\", \"positive\"),\n",
        "]\n",
        "\n",
        "INPUTS_SHOULD_ABSTAIN = [\n",
        "    (\"\", \"abstain\"),\n",
        "    (\"Is this product good?\", \"abstain\"),\n",
        "    (\"The weather is nice today.\", \"abstain\"),\n",
        "    (\"asdf qwerty zxcv\", \"abstain\"),\n",
        "    (\"1\", \"abstain\"),\n",
        "]\n",
        "\n",
        "print(f\"Training: {len(REVIEWS_TRAIN)} | Test: {len(REVIEWS_TEST)} | Challenge: {len(REVIEWS_CHALLENGE)} | Should abstain: {len(INPUTS_SHOULD_ABSTAIN)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìê Traditional NLP: TF-IDF + Logistic Regression\n",
        "\n",
        "**Pipeline:** text ‚Üí tokenize + **TF-IDF** (hand-crafted features) ‚Üí **logistic regression** (trained on labels).\n",
        "\n",
        "**Characteristics:** One model per task, needs labeled data, fast at inference, **cannot go beyond** what it was trained on (novel phrasing, sarcasm, slang often fail)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "texts = [t for t, _ in REVIEWS_TRAIN]\n",
        "labels = [label for _, label in REVIEWS_TRAIN]\n",
        "\n",
        "pipe = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(max_features=500, ngram_range=(1, 2))),\n",
        "    (\"clf\", LogisticRegression(max_iter=500, random_state=42)),\n",
        "])\n",
        "pipe.fit(texts, labels)\n",
        "\n",
        "def run_traditional(reviews):\n",
        "    return list(pipe.predict(reviews))\n",
        "\n",
        "print(\"Traditional model trained. Use run_traditional(reviews) to predict.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£ Part 1: In-distribution (reviews similar to training)\n",
        "\n",
        "Both approaches should get these right."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trad_test = run_traditional(REVIEWS_TEST)\n",
        "print(\"Traditional (TF-IDF + LogReg):\")\n",
        "for review, pred in zip(REVIEWS_TEST, trad_test):\n",
        "    print(f\"  {review!r} ‚Üí {pred}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§ñ Generative AI: instruction + model, no training\n",
        "\n",
        "**Pipeline:** prompt + review ‚Üí LLM (Groq) ‚Üí parse reply. No feature engineering, no training for this task. **Can go beyond training** (nuance, sarcasm, slang), but can also **generate when it shouldn't** (e.g. assign sentiment to empty or off-topic input)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_generative(reviews):\n",
        "    client = get_groq_client()\n",
        "    predictions = []\n",
        "    for review in reviews:\n",
        "        response = client.responses.create(\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            input=(\n",
        "                \"Classify the sentiment of this customer review as exactly one \"\n",
        "                \"word: positive, negative, or neutral. Reply with only that word.\\n\\n\"\n",
        "                f\"Review: {review}\"\n",
        "            ),\n",
        "            temperature=0,\n",
        "            max_output_tokens=10,\n",
        "        )\n",
        "        out = (response.output_text or \"\").strip().lower()\n",
        "        if \"positive\" in out:\n",
        "            pred = \"positive\"\n",
        "        elif \"negative\" in out:\n",
        "            pred = \"negative\"\n",
        "        else:\n",
        "            pred = \"neutral\"\n",
        "        predictions.append(pred)\n",
        "    return predictions\n",
        "\n",
        "print(\"run_generative(reviews) defined. Requires GROQ_API_KEY.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gen_test = run_generative(REVIEWS_TEST)\n",
        "print(\"Generative (Groq, no training):\")\n",
        "for review, pred in zip(REVIEWS_TEST, gen_test):\n",
        "    print(f\"  {review!r} ‚Üí {pred}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2Ô∏è‚É£ Part 2: Beyond training (nuance, sarcasm, slang, negation)\n",
        "\n",
        "These phrasings were **not** in the training set. Traditional often wrong (‚úó); generative usually right (‚úì). **Lesson:** Traditional cannot go beyond training; generative can."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "challenge_texts = [t for t, _ in REVIEWS_CHALLENGE]\n",
        "expected = [label for _, label in REVIEWS_CHALLENGE]\n",
        "trad_challenge = run_traditional(challenge_texts)\n",
        "gen_challenge = run_generative(challenge_texts)\n",
        "\n",
        "print(\"Expected | Traditional | Generative\\n\")\n",
        "for i, (text, exp) in enumerate(zip(challenge_texts, expected)):\n",
        "    t_pred = trad_challenge[i]\n",
        "    g_pred = gen_challenge[i]\n",
        "    t_ok = \"‚úì\" if t_pred == exp else \"‚úó\"\n",
        "    g_ok = \"‚úì\" if g_pred == exp else \"‚úó\"\n",
        "    print(f\"  {text!r}\")\n",
        "    print(f\"    Exp: {exp} | Trad: {t_pred} {t_ok} | Gen: {g_pred} {g_ok}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3Ô∏è‚É£ Part 3: When the model should NOT generate (ideal: abstain)\n",
        "\n",
        "Input is **not** a review (empty, question, off-topic, gibberish). Ideal = abstain / \"not applicable\". Both often **output a label anyway**; generative in particular tends to **generate something even when it shouldn't**. **Lesson:** A negative of generative AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "abstain_texts = [t for t, _ in INPUTS_SHOULD_ABSTAIN]\n",
        "should_list = [s for _, s in INPUTS_SHOULD_ABSTAIN]\n",
        "trad_abstain = run_traditional(abstain_texts)\n",
        "gen_abstain = run_generative(abstain_texts)\n",
        "\n",
        "print(\"Input (short) | Should | Traditional | Generative\\n\")\n",
        "for i, text in enumerate(abstain_texts):\n",
        "    snippet = (text[:20] + \"‚Ä¶\") if len(text) > 20 else (text or \"(empty)\")\n",
        "    print(f\"  {snippet!r} | {should_list[i]} | {trad_abstain[i]} | {gen_abstain[i]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìã Summary: Positives and negatives of generative AI\n",
        "\n",
        "**Positives:** Can go beyond training (nuance, sarcasm, slang); one model, many tasks; no training for this task.\n",
        "\n",
        "**Negatives:** Generates something even when it shouldn't (e.g. empty/off-topic ‚Üí still outputs a label); hallucination; cost and latency; non-determinism.\n",
        "\n",
        "**More lessons:**\n",
        "- **Interpretability:** Traditional = explainable (weights); generative = black box.\n",
        "- **Consistency:** Traditional = same input ‚Üí same output; generative = can vary.\n",
        "- **Cost at scale:** Traditional = cheap inference; generative = pay per token.\n",
        "- **Privacy:** Traditional = data stays local; generative = text sent to API.\n",
        "- **Latency:** Traditional = ms; generative = network + generation.\n",
        "- **Task boundaries:** Traditional = one task; generative = flexible but softer fence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Notebook complete. Re-run any cell to re-run that step.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö Additional reading\n",
        "\n",
        "**YouTube (verified)**  \n",
        "- [Sentiment Analysis with Transformers](https://www.youtube.com/watch?v=cXWuSWX0Va0) ‚Äî Hugging Face + Python.  \n",
        "- [YouTube Sentiment Analysis with DistilBERT](https://www.youtube.com/watch?v=FIGoOP2b0V4) ‚Äî NLP pipeline with Hugging Face.\n",
        "\n",
        "**Blogs (popular)**  \n",
        "- [Getting Started with Sentiment Analysis using Python](https://huggingface.co/blog/sentiment-analysis-python) ‚Äî Hugging Face blog.  \n",
        "- [Hugging Face NLP course](https://huggingface.co/course/chapter1/1) ‚Äî Tokenization, models, and tasks."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
