{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://toppng.com/uploads/preview/linkedin-logo-png-photo-116602552293wtc4qogql.png\" width=\"20\" height=\"20\" /> [Bharath Hemachandran](https://www.linkedin.com/in/bharath-hemachandran/)\n",
        "\n",
        "# ðŸ§© Phase 3: Multi-Step Agent with MCP\n",
        "\n",
        "Same MCP (Hugging Face), but a **multi-step** prompt: the model will make **several tool calls** in one run (e.g. search, then summarize). No approvalâ€”<code>require_approval: \"never\"</code>.\n",
        "\n",
        "<div style=\"background: #e1f5fe; padding: 14px; border-radius: 8px; border-left: 4px solid #0288d1;\">\n",
        "<strong>ðŸŽ¯ What you'll do:</strong> Ask the model to search Hugging Face for trending models and then summarize the top 2. You'll see multiple <code>mcp_call</code> steps in the output.\n",
        "</div>\n",
        "\n",
        "### ðŸ“‹ Notebook objective (table of contents)\n",
        "\n",
        "This notebook covers:\n",
        "- **Setup** â€” OpenAI client and API keys (GROQ + optional HF_TOKEN)\n",
        "- **MCP tool** â€” Same Hugging Face MCP config as Phase 2\n",
        "- **Multi-step prompt** â€” Request that triggers multiple tool calls in one run\n",
        "- **API call** â€” Groq Responses API with tools; model searches then summarizes\n",
        "- **mcp_call steps** â€” Inspecting each tool-call item in <code>response.output</code>\n",
        "- **Additional reading** â€” MCP and agent workflows\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”§ Setup (run once)\n",
        "\n",
        "Same as Phase 2: **openai** and API keys (GROQ + optional HF_TOKEN)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "if not os.environ.get(\"GROQ_API_KEY\"):\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass(\"Paste your GROQ_API_KEY: \")\n",
        "if not os.environ.get(\"HF_TOKEN\"):\n",
        "    tok = getpass(\"Paste your HF_TOKEN (or press Enter to skip): \")\n",
        "    if tok:\n",
        "        os.environ[\"HF_TOKEN\"] = tok\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "def get_groq_client():\n",
        "    return OpenAI(\n",
        "        api_key=os.environ[\"GROQ_API_KEY\"],\n",
        "        base_url=\"https://api.groq.com/openai/v1\",\n",
        "    )\n",
        "\n",
        "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
        "print(\"âœ… Groq client ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”§ MCP tool (same as Phase 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mcp_tool = {\n",
        "    \"type\": \"mcp\",\n",
        "    \"server_label\": \"Huggingface\",\n",
        "    \"server_url\": \"https://huggingface.co/mcp\",\n",
        "    \"server_description\": \"Search and access AI models from Hugging Face\",\n",
        "    \"require_approval\": \"never\",\n",
        "}\n",
        "if HF_TOKEN:\n",
        "    mcp_tool[\"headers\"] = {\"Authorization\": f\"Bearer {HF_TOKEN}\"}\n",
        "\n",
        "print(\"MCP tool: Hugging Face\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸš€ Multi-step prompt\n",
        "\n",
        "The prompt asks for **two steps**: (1) search for trending text-generation models, (2) summarize the top 2. The model may issue **multiple** <code>mcp_call</code> items before returning the final text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client = get_groq_client()\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"openai/gpt-oss-120b\",\n",
        "    input=(\n",
        "        \"Search Hugging Face for trending text-generation models. \"\n",
        "        \"Then summarize the top 2 in one short paragraph.\"\n",
        "    ),\n",
        "    tools=[mcp_tool],\n",
        ")\n",
        "\n",
        "print(\"--- output_text ---\")\n",
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“‹ mcp_call steps\n",
        "\n",
        "Each tool call appears as an item with <code>type == \"mcp_call\"</code>. Here we print a short preview of each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"--- mcp_call steps ---\")\n",
        "for item in response.output:\n",
        "    if getattr(item, \"type\", None) == \"mcp_call\":\n",
        "        name = getattr(item, \"name\", \"?\")\n",
        "        out = str(getattr(item, \"output\", \"\"))[:200]\n",
        "        print(f\"  {name}: {out}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"âœ… Phase 3 complete. Next: build your own MCP or use Cursor agents.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“š Additional reading\n",
        "\n",
        "**YouTube (verified)**  \n",
        "- [The Model Context Protocol (MCP)](https://www.youtube.com/watch?v=CQywdSdi5iA) â€” Anthropic: MCP and tool integration.  \n",
        "- [Model Context Protocol, clearly explained](https://www.youtube.com/watch?v=7j_NE6Pjv-E) â€” Multi-step agents and external tools.\n",
        "\n",
        "**Blogs (popular)**  \n",
        "- [Model Context Protocol](https://modelcontextprotocol.io) â€” Official site: protocol, servers, clients.  \n",
        "- [Groq Blog â€“ MCP and connectors](https://groq.com/blog) â€” Groq: MCP support and agent workflows."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
