{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://toppng.com/uploads/preview/linkedin-logo-png-photo-116602552293wtc4qogql.png\" width=\"20\" height=\"20\" /> [Bharath Hemachandran](https://www.linkedin.com/in/bharath-hemachandran/)\n",
        "\n",
        "# üß© Phase 3: Agents + MCP (single-agent intro)\n",
        "\n",
        "In Phase 2 you gave a model **one MCP server (Hugging Face)** so it could call tools. In this phase, you‚Äôll see how that becomes a simple **agent**: a model that can **decide what to do next**, use tools, and work toward a goal.\n",
        "\n",
        "<div style=\"background: #e1f5fe; padding: 14px; border-radius: 8px; border-left: 4px solid #0288d1;\">\n",
        "<strong>üéØ What you'll do:</strong> Start from the Phase 2 MCP setup, define what an <strong>agent</strong> is, run a <strong>single agent</strong> that uses tools (including the Hugging Face MCP server), inspect its tool calls step by step, and briefly compare popular agent frameworks.\n",
        "</div>\n",
        "\n",
        "### üìã Notebook objective (table of contents)\n",
        "\n",
        "This notebook covers:\n",
        "- **Recap from Phase 2** ‚Äî Reuse Groq + Hugging Face MCP setup\n",
        "- **What is an agent?** ‚Äî Intuition and mental model\n",
        "- **Single-agent pattern** ‚Äî One agent using tools (including MCP)\n",
        "- **Implement a simple agent with Groq** ‚Äî Step-by-step run with `responses.create`\n",
        "- **Inspect tool calls (`mcp_call`)** ‚Äî See how the agent actually used MCP\n",
        "- **Compare popular agent frameworks** ‚Äî LangChain, LlamaIndex, crewAI, AutoGen (conceptual)\n",
        "- **Exercises** ‚Äî Agent vs API call, inspect mcp_call, prompt vs extra tools\n",
        "- **Additional reading** ‚Äî Agents, tools, and MCP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Setup (run once)\n",
        "\n",
        "Same as Phase 2: install **openai** and set API keys (GROQ + optional HF_TOKEN). We‚Äôll then reuse that setup to build a very simple **agent** on top."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "if not os.environ.get(\"GROQ_API_KEY\"):\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass(\"Paste your GROQ_API_KEY: \")\n",
        "if not os.environ.get(\"HF_TOKEN\"):\n",
        "    tok = getpass(\"Paste your HF_TOKEN (or press Enter to skip): \")\n",
        "    if tok:\n",
        "        os.environ[\"HF_TOKEN\"] = tok\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "def get_groq_client():\n",
        "    return OpenAI(\n",
        "        api_key=os.environ[\"GROQ_API_KEY\"],\n",
        "        base_url=\"https://api.groq.com/openai/v1\",\n",
        "    )\n",
        "\n",
        "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
        "print(\"‚úÖ Groq client ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß MCP tool (same as Phase 2)\n",
        "\n",
        "We‚Äôll use the <strong>same Hugging Face MCP tool</strong> from Phase 2. In this notebook, it becomes one of the tools our <strong>agent</strong> is allowed to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mcp_tool = {\n",
        "    \"type\": \"mcp\",\n",
        "    \"server_label\": \"Huggingface\",\n",
        "    \"server_url\": \"https://huggingface.co/mcp\",\n",
        "    \"server_description\": \"Search and access AI models from Hugging Face\",\n",
        "    \"require_approval\": \"never\",\n",
        "}\n",
        "if HF_TOKEN:\n",
        "    mcp_tool[\"headers\"] = {\"Authorization\": f\"Bearer {HF_TOKEN}\"}\n",
        "\n",
        "print(\"MCP tool: Hugging Face\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß© From tools to agents (recap of Phase 2)\n",
        "\n",
        "In **Phase 2**, you:\n",
        "\n",
        "- Configured Groq‚Äôs `responses.create` with **one MCP tool** (Hugging Face search).\n",
        "- Let the model **call that tool** when it needed more information.\n",
        "- Read the final answer from `response.output_text` and inspected `mcp_call` items.\n",
        "\n",
        "You can think of that as the **building block of an agent**:\n",
        "\n",
        "- The **model** reasons about what it needs.\n",
        "- The **client** (Groq) exposes **tools** (via MCP) that the model can call.\n",
        "- The **MCP server** (Hugging Face) runs the actual work (search, read, etc.).\n",
        "\n",
        "In this phase we put a thin ‚Äúagent‚Äù wrapper around this pattern and make the idea of an agent explicit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† What is an \"agent\" in this context?\n",
        "\n",
        "In this course, an **agent** is:\n",
        "\n",
        "> A loop around a model that can **decide what to do next**, call **tools** (like MCP servers), and gradually work toward a **goal**, instead of just answering once.\n",
        "\n",
        "Very simple agents can be just **one model call** that is allowed to use tools (the client handles tool calls for you). More advanced agents add things like:\n",
        "\n",
        "- **State / memory** ‚Äî The agent remembers past steps.\n",
        "- **Planning** ‚Äî The agent decomposes a big task into smaller actions.\n",
        "- **Multiple tools** ‚Äî The agent chooses between tools (search, database, code, etc.).\n",
        "- **Multi-agent setups** ‚Äî Several agents talk to each other (out of scope for this phase).\n",
        "\n",
        "In this notebook we keep it simple: **one agent, one MCP server, one goal**.\n",
        "\n",
        "## üöÄ Single-agent pattern with Groq + MCP\n",
        "\n",
        "We‚Äôll treat a single `responses.create` call (with tools enabled) as a **simple agent run**:\n",
        "\n",
        "1. You give the agent a **goal** in natural language.\n",
        "2. The model decides whether to call the **Hugging Face MCP tool**.\n",
        "3. The MCP server runs the tool and returns results.\n",
        "4. The model uses those results to produce a final answer.\n",
        "\n",
        "You‚Äôll see these steps reflected as `mcp_call` items inside `response.output`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client = get_groq_client()\n",
        "\n",
        "def run_agent(task: str):\n",
        "    \"\"\"Very simple single-agent run using Groq + Hugging Face MCP.\n",
        "\n",
        "    - Takes a natural-language task.\n",
        "    - Lets the model decide if/when to call the MCP tool.\n",
        "    - Returns the full response so we can inspect tool calls.\n",
        "    \"\"\"\n",
        "    response = client.responses.create(\n",
        "        model=\"openai/gpt-oss-120b\",\n",
        "        input=task,\n",
        "        tools=[mcp_tool],\n",
        "    )\n",
        "    return response\n",
        "\n",
        "# Example: give the agent a clear goal that requires Hugging Face.\n",
        "example_task = (\n",
        "    \"Act as a model search agent. Use Hugging Face to find trending \"\n",
        "    \"text-generation models and then summarize the top 2 in one short paragraph.\"\n",
        ")\n",
        "\n",
        "response = run_agent(example_task)\n",
        "\n",
        "print(\"--- agent output_text ---\")\n",
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìã Inspecting the agent's tool calls (`mcp_call`)\n",
        "\n",
        "Each time the agent (model) uses the Hugging Face MCP tool, you‚Äôll see an item in `response.output` with <code>type == \"mcp_call\"</code>.\n",
        "\n",
        "We‚Äôll print a short preview of each to see **what tools the agent chose, in what order, and with what outputs**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"--- mcp_call steps ---\")\n",
        "for item in response.output:\n",
        "    if getattr(item, \"type\", None) == \"mcp_call\":\n",
        "        name = getattr(item, \"name\", \"?\")\n",
        "        out = str(getattr(item, \"output\", \"\"))[:200]\n",
        "        print(f\"  {name}: {out}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"‚úÖ Phase 3 complete. You now have a simple single agent using MCP.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úèÔ∏è Exercises\n",
        "\n",
        "*Use only what you learned in this phase (what an agent is, single agent + tools, mcp_call, frameworks).*\n",
        "\n",
        "1. **Agent vs one-off API call**  \n",
        "   In your own words, what makes a **single agent** (like the one we built) different from a **one-off API call** that has no tools? Answer in one or two sentences.\n",
        "\n",
        "2. **Inspect tool usage**  \n",
        "   After running the agent (the cell that asks for trending text-generation models and summarizes the top 2), look at the `mcp_call` steps in `response.output`. How many tool calls did the agent make? For each call, what is the **name** of the tool and what did it do in one short phrase (e.g. \"search for models\")?\n",
        "\n",
        "3. **Prompt vs extra tools**  \n",
        "   Suppose you want the agent to (a) search Hugging Face and (b) return the summary **only as bullet points**. Would you add another MCP server, or change the prompt, or both? Justify in one or two sentences using what you learned about agents and tools."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö Additional reading\n",
        "\n",
        "**YouTube (verified)**  \n",
        "- [The Model Context Protocol (MCP)](https://www.youtube.com/watch?v=CQywdSdi5iA) ‚Äî Anthropic: MCP and tool integration.  \n",
        "- [Model Context Protocol, clearly explained](https://www.youtube.com/watch?v=7j_NE6Pjv-E) ‚Äî Multi-step agents and external tools.  \n",
        "- [LangChain Agents overview](https://www.youtube.com/results?search_query=langchain+agents) ‚Äî How LangChain structures tools, agents, and planning.\n",
        "\n",
        "**Blogs / docs (popular)**  \n",
        "- [Model Context Protocol](https://modelcontextprotocol.io) ‚Äî Official site: protocol, servers, clients.  \n",
        "- [Groq Blog ‚Äì MCP and connectors](https://groq.com/blog) ‚Äî Groq: MCP support and agent workflows.  \n",
        "- [LangChain Agents](https://python.langchain.com/docs/modules/agents/) ‚Äî Agents, tools, and tool-calling orchestration.  \n",
        "- [LlamaIndex agents](https://docs.llamaindex.ai) ‚Äî Index-centric agents and tool use.  \n",
        "- [crewAI](https://www.crewai.com/) and [AutoGen](https://aka.ms/autogen) ‚Äî Multi-agent orchestration frameworks (beyond this phase)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
