{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://toppng.com/uploads/preview/linkedin-logo-png-photo-116602552293wtc4qogql.png\" width=\"20\" height=\"20\" /> [Bharath Hemachandran](https://www.linkedin.com/in/bharath-hemachandran/)\n",
        "\n",
        "# ðŸ”Œ Phase 2: Groq + One MCP (Hugging Face)\n",
        "\n",
        "Add **one MCP server** so the model can use **tools** (e.g. search Hugging Face). No approval flowâ€”<code>require_approval: \"never\"</code>â€”so the run completes in one go.\n",
        "\n",
        "<div style=\"background: #fce4ec; padding: 14px; border-radius: 8px; border-left: 4px solid #c2185b;\">\n",
        "<strong>ðŸŽ¯ What you'll do:</strong> Call the Groq API with a single MCP tool (Hugging Face). The model will use the tool and return text + tool outputs.\n",
        "</div>\n",
        "\n",
        "### ðŸ“‹ Notebook objective (table of contents)\n",
        "\n",
        "This notebook covers:\n",
        "- **Setup** â€” Install OpenAI client\n",
        "- **API keys** â€” GROQ_API_KEY (required), HF_TOKEN (optional)\n",
        "- **Define the MCP tool** â€” type, server URL, require_approval: \"never\"\n",
        "- **Call Groq with the MCP tool** â€” One request; model uses tool and returns text\n",
        "- **Output items** â€” Types in <code>response.output</code> (e.g. mcp_call)\n",
        "- **Additional reading** â€” MCP spec and Groq docs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”§ Setup (run once)\n",
        "\n",
        "Install **openai**. On Colab, run this cell first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ”‘ API keys\n",
        "\n",
        "- **GROQ_API_KEY** â€” required. Get it at [console.groq.com](https://console.groq.com/keys).<br>\n",
        "- **HF_TOKEN** (optional) â€” for Hugging Face MCP; improves rate limits. Get it at [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "if not os.environ.get(\"GROQ_API_KEY\"):\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass(\"Paste your GROQ_API_KEY: \")\n",
        "if not os.environ.get(\"HF_TOKEN\"):\n",
        "    tok = getpass(\"Paste your HF_TOKEN (or press Enter to skip): \")\n",
        "    if tok:\n",
        "        os.environ[\"HF_TOKEN\"] = tok\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "def get_groq_client():\n",
        "    return OpenAI(\n",
        "        api_key=os.environ[\"GROQ_API_KEY\"],\n",
        "        base_url=\"https://api.groq.com/openai/v1\",\n",
        "    )\n",
        "\n",
        "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
        "print(\"âœ… Groq client ready.\" if os.environ.get(\"GROQ_API_KEY\") else \"Need GROQ_API_KEY.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”§ Define the MCP tool\n",
        "\n",
        "One tool entry: <code>type: \"mcp\"</code>, server URL, and <code>require_approval: \"never\"</code> so the run doesn't wait for approval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mcp_tool = {\n",
        "    \"type\": \"mcp\",\n",
        "    \"server_label\": \"Huggingface\",\n",
        "    \"server_url\": \"https://huggingface.co/mcp\",\n",
        "    \"server_description\": \"Search and access AI models from Hugging Face\",\n",
        "    \"require_approval\": \"never\",\n",
        "}\n",
        "if HF_TOKEN:\n",
        "    mcp_tool[\"headers\"] = {\"Authorization\": f\"Bearer {HF_TOKEN}\"}\n",
        "\n",
        "print(\"MCP tool: Hugging Face (require_approval: never)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸš€ Call Groq with the MCP tool\n",
        "\n",
        "We use a model that supports tools (e.g. <code>openai/gpt-oss-120b</code>). The model may issue **tool calls**; with <code>require_approval: \"never\"</code> they run automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client = get_groq_client()\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"openai/gpt-oss-120b\",\n",
        "    input=\"What models are trending on Hugging Face? List up to 3.\",\n",
        "    tools=[mcp_tool],\n",
        ")\n",
        "\n",
        "print(\"--- output_text ---\")\n",
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“¦ Output items (types)\n",
        "\n",
        "The <code>response.output</code> list can contain text and tool-related items (e.g. <code>mcp_call</code>)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"--- output item types ---\")\n",
        "for item in response.output:\n",
        "    t = getattr(item, \"type\", item)\n",
        "    print(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"âœ… Phase 2 complete. Next: Phase 3 (multi-step MCP agent).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“š Additional reading\n",
        "\n",
        "**YouTube (verified)**  \n",
        "- [The Model Context Protocol (MCP)](https://www.youtube.com/watch?v=CQywdSdi5iA) â€” Anthropic: MCP intro and why it matters.  \n",
        "- [Model Context Protocol, clearly explained](https://www.youtube.com/watch?v=7j_NE6Pjv-E) â€” Why MCP matters for connecting AI to tools.\n",
        "\n",
        "**Blogs (popular)**  \n",
        "- [Model Context Protocol â€“ Specification](https://modelcontextprotocol.io/specification/latest) â€” Official MCP spec: tools, resources, lifecycle.  \n",
        "- [Groq API Reference](https://console.groq.com/docs) â€” Groq docs: Responses API, tools, MCP connectors."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
